# 扩散模型学习

## 数学基础

条件概率公式和高斯分布的KL散度

- 条件概率的一般公式

$$
P(A,B,C)=P(C|B,A)P(B,A)=P(C|B,A)P(B|A)P(A)\\P(B,C|A) = P(B,A)P(C|A,B)
$$

- 基于马尔科夫假设的条件概率

  

- 参数重整化



## VAE

机器学习的几个topic

监督学习：分类/回归

无监督学习：概率密度估计

监督学习中的概率建模:

- 基于特征在推断目标

对样本X 的概率分布P(X)做估计

用概率的语言描述这个世界

- 这个世界上的一切都是

什么是蒙特卡洛方法：

使用随机性解决确定性问题

常见有计算期望

背后的依据：大数定律

缺点：高维空间上的效率非常低

计算$\pi$，在二维空间的解法：

sample n 个[-1,1]之间的均匀随机变量

推广到n维空间

高斯分布对仿射变换是封闭



## DDPM（Denoising Diffusion Probabilistic Models）

DDPM共分为两个过程，前向过程和去噪过程。前向过程就是利用模型不断预测加噪前的图片，从而还原出原图像。

### 总览

(1) 前向加噪

前向加噪的公式如下：
$$
q(X_t|X_(t-1)) =N(X_t;\sqrt{1-\beta_t}X_{t-1},\beta_tI)
$$
其中$\beta_t$是0到1的小数，并且满足$\beta_1<\beta_2<\dots<\beta_T$


$$
q(X_t|X_0) = N(X_t;\sqrt{\bar{\alpha}_t}X_0,(1-\bar{\alpha}_t)I)
$$
或者写为
$$
X_t=\sqrt{\bar{\alpha}_t}X_0 + \sqrt{1-\bar{\alpha}_t}\epsilon
$$
其中，$\alpha_t$的定义为$1-\beta_t$。

(3)后验的均值和方差

$q(X_{t-1}|X_t,X_0)$的均值$\tilde{\mu}(X_t,X_0)$以及方差$\tilde{\beta}_t$分别为：
$$
\tilde{\mu}(X_t,X_0) = \frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_t}X_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}X_t
$$

## Cascade video Diffusion

由粗到细的视频生成方法，包括先生成关键帧，时间插值，空间上超分

## Delta Denoiseing Score

- SDS 
  $$
  \nabla_{\theta}\mathcal{L}_{diff }=(\epsilon^w_\phi(\mathbf{z}_t ,y,t)-\mathbf{\epsilon)\frac{\partial\epsilon^w_{\phi}(\mathbf{z},y,t)}{\partial{\mathbf{z}_t}}}\frac{\partial\mathbf{z}_t}{\partial{\theta}}
  $$
  

$$
\nabla_{\theta}\mathcal{L}_{SDS }(\mathbf{z},y,\epsilon,t)=(\epsilon^w_\phi(\mathbf{z}_t,y,t) -\mathbf{\epsilon)\frac{\partial\mathbf{z}_t}{\partial{\theta}}}
$$

其中$\theta$是将图像进行参数化，其可以是生成图像的任意可导参数。

## Stable Diffusion

不是在像素空间进行Diffusion过程，而是在vae encode 之后的隐空间进行diffusion过程。隐变量的维度小于像素空间的维度，计算复杂度更小。使用attention机制将condition引入（cross attention）

## Score-base Diffusion model

- 分数动力和郎之万Langevin采样（郎之万动力学）

- 分数指的就是一个样本的对数似然函数
- 知道一个样本的对数似然函数，就可以通过郎之万采样将样本采样出来。

![image-20240416130925949](C:\Users\19475\AppData\Roaming\Typora\typora-user-images\image-20240416130925949.png)

这个公式能够匹配原因是将分数网络的值替换为原分数的

## Score

生成模型的本质是找到一个概率密度函数，

- 概率密度函数大于等 于0
- 在样本空间对概率密度做积分为1

假设模型可以拟合一个实函数$f_\theta(x)\in R$，
$$
P_\theta = \frac{e^{f_\theta (x)}}{z_\theta}
$$
$z_\theta$

## DDIM

去马尔科夫化，训练过程与DDPM一样

deterministic 多样性不如DDPM

