# 扩散模型学习

## 数学基础

条件概率公式和高斯分布的KL散度

- 条件概率的一般公式

$$
P(A,B,C)=P(C|B,A)P(B,A)=P(C|B,A)P(B|A)P(A)\\P(B,C|A) = P(B,A)P(C|A,B)
$$

- 基于马尔科夫假设的条件概率

  

- 参数重整化



## VAE

机器学习的几个topic

监督学习：分类/回归

无监督学习：概率密度估计

监督学习中的概率建模:

- 基于特征在推断目标

对样本X 的概率分布P(X)做估计

用概率的语言描述这个世界

- 这个世界上的一切都是

什么是蒙特卡洛方法：

使用随机性解决确定性问题

常见有计算期望

背后的依据：大数定律

缺点：高维空间上的效率非常低

计算$\pi$，在二维空间的解法：

sample n 个[-1,1]之间的均匀随机变量

推广到n维空间

高斯分布对仿射变换是封闭



## DDPM（Denoising Diffusion Probabilistic Models）

DDPM共分为两个过程，前向过程和去噪过程。前向过程就是利用模型不断预测加噪前的图片，从而还原出原图像。

### 总览

(1) 前向加噪

前向加噪的公式如下：
$$
q(X_t|X_(t-1)) =N(X_t;\sqrt{1-\beta_t}X_{t-1},\beta_tI)
$$
其中$\beta_t$是0到1的小数，并且满足$\beta_1<\beta_2<\dots<\beta_T$


$$
q(X_t|X_0) = N(X_t;\sqrt{\bar{\alpha}_t}X_0,(1-\bar{\alpha}_t)I)
$$
或者写为
$$
X_t=\sqrt{\bar{\alpha}_t}X_0 + \sqrt{1-\bar{\alpha}_t}\epsilon
$$
其中，$\alpha_t$的定义为$1-\beta_t$。

(3)后验的均值和方差

$q(X_{t-1}|X_t,X_0)$的均值$\tilde{\mu}(X_t,X_0)$以及方差$\tilde{\beta}_t$分别为：
$$
\tilde{\mu}(X_t,X_0) = \frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_t}X_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}X_t
$$

## Cascade video Diffusion

由粗到细的视频生成方法，包括先生成关键帧，时间插值，空间上超分

## Delta Denoiseing Score

- SDS 
  $$
  \nabla_{\theta}\mathcal{L}_{diff }=(\epsilon^w_\phi(\mathbf{z}_t ,y,t)-\mathbf{\epsilon)\frac{\partial\epsilon^w_{\phi}(\mathbf{z},y,t)}{\partial{\mathbf{z}_t}}}\frac{\partial\mathbf{z}_t}{\partial{\theta}}
  $$
  

$$
\nabla_{\theta}\mathcal{L}_{SDS }(\mathbf{z},y,\epsilon,t)=(\epsilon^w_\phi(\mathbf{z}_t,y,t) -\mathbf{\epsilon)\frac{\partial\mathbf{z}_t}{\partial{\theta}}}
$$

其中$\theta$是将图像进行参数化，其可以是生成图像的任意可导参数。

## Stable Diffusion

不是在像素空间进行Diffusion过程，而是在vae encode 之后的隐空间进行diffusion过程。隐变量的维度小于像素空间的维度，计算复杂度更小。使用attention机制将condition引入（cross attention）

## Score-base Diffusion model

- 分数动力和郎之万Langevin采样（郎之万动力学）

- 分数指的就是一个样本的对数似然函数
- 知道一个样本的对数似然函数，就可以通过郎之万采样将样本采样出来。

![image-20240416130925949](C:\Users\19475\AppData\Roaming\Typora\typora-user-images\image-20240416130925949.png)

这个公式能够匹配原因是将分数网络的值替换为原分数的

## Score

生成模型的本质是找到一个概率密度函数，

- 概率密度函数大于等 于0
- 在样本空间对概率密度做积分为1

假设模型可以拟合一个实函数$f_\theta(x)\in R$，
$$
P_\theta = \frac{e^{f_\theta (x)}}{z_\theta}
$$
$z_\theta$

## DDIM

去马尔科夫化，训练过程与DDPM一样

deterministic 多样性不如DDPM

# 1. Classifier Guidance

用贝叶斯概率可以将条件生成概率进行分解

如下式：
$$
\begin{align*}  
\nabla \log p(x_t \mid y) &= \nabla \log \left( \frac{p(x_t) \, p(y \mid x_t)}{p(y)} \right) \\
&= \nabla \log p(x_t) + \nabla \log p(y \mid x_t) - \nabla \log p(y) \\
&= \underbrace{\nabla \log p(x_t)}_{\text{unconditional score}} + \underbrace{\nabla \log p(y \mid x_t)}_{\text{classifier gradient}}  
\end{align*}
$$
从上式可以看到，Classifier Guidance**条件生成只需额外添加一个classifier的梯度来引导。从成本上看，Classifier Guidance 需要训练噪声数据版本的classifier网络，推理时每一步都需要额外计算classifier的梯度**

也就是使用Classifier Guidance可以节约训练成本，但是会增加推理成本。

# 2. Classifier-free Guidance

**Classifier Guidance 使用显式的分类器引导条件生成有几个问题**：一是需要额外训练一个噪声版本的[图像分类器](https://zhida.zhihu.com/search?q=图像分类器&zhida_source=entity&is_preview=1)。二是该分类器的质量会影响按类别生成的效果。三是通过梯度更新图像会导致[对抗攻击效应](https://zhida.zhihu.com/search?q=对抗攻击效应&zhida_source=entity&is_preview=1)，生成图像可能会通过人眼不可察觉的细节欺骗分类器，实际上并没有按条件生成。

2022年谷歌提出**Classifier-Free Guidance方**案，可以规避上述问题，而且可以通过调节引导权重，控制生成图像的逼真性和多样性的平衡，**DALL·E 2和Imagen等模型都是以它为基础进行训练和推理**

Classifier-Free Guidance的权重用于控制图像生成的逼真性和多样性。

**Classifier-Free Guidance的核心是通过一个[隐式分类器](https://zhida.zhihu.com/search?q=隐式分类器&zhida_source=entity&is_preview=1)来替代显示分类器，而无需直接计算显式分类器及其梯度**。根据[贝叶斯公式](https://zhida.zhihu.com/search?q=贝叶斯公式&zhida_source=entity&is_preview=1)，**分类器的梯度可以用条件生成概率和无条件生成概率表示**：
$$
\begin{align*}  
\nabla_{x_t} \log p(y \mid x_t) &= \nabla_{x_t} \log p(x_t \mid y) - \nabla_{x_t} \log p(x_t) \\
&= -\frac{1}{\sqrt{1 - \bar{\alpha}_t}} \left( \epsilon_\theta(x_t, t, y) - \epsilon_\theta(x_t, t) \right)  
\end{align*}
$$
把上面的[分类器梯度](https://zhida.zhihu.com/search?q=分类器梯度&zhida_source=entity&is_preview=1)代入到**classifier guidance**的分类器梯度中可得：
$$
\begin{align*}  
\bar{\epsilon}_\theta (x_t, t, y) &= \epsilon_\theta (x_t, t, y) - \sqrt{1 - \bar{\alpha}_t} w \nabla_{x_t} \log p(y \mid x_t) \\
&= \epsilon_\theta (x_t, t, y) + w \left( \epsilon_\theta (x_t, t, y) - \epsilon_\theta (x_t, t) \right) \\
&= (w + 1) \epsilon_\theta (x_t, t, y) - w \epsilon_\theta (x_t, t)  
\end{align*}
$$
由上可知，新的生成过程**不再依赖显示的classifier**，因而解决了上述Classifier Guidance的几个问题。

**总的来说，训练时，Classifier-Free Guidance需要训练两个模型，一个是无条件[生成模型](https://zhida.zhihu.com/search?q=生成模型&zhida_source=entity&is_preview=1)，另一个是条件生成模型。**但这两个模型可以用同一个模型表示，**训练时只需要以一定概率将条件置空即可。**

**推理时，最终结果可以由条件生成和无条件生成的线性外推获得，生成效果可以引导系数可以调节，控制生成样本的逼真性和多样性的平衡。**

# 3. Diffusion Model 生成相关指标

